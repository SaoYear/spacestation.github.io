<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://saoyear.github.io</id>
    <title>Personal Page of Nian</title>
    <updated>2020-07-27T09:36:49.309Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://saoyear.github.io"/>
    <link rel="self" href="https://saoyear.github.io/atom.xml"/>
    <subtitle>I&apos;m Nian. Add me on Brawl Stars: #VVRRUJ0</subtitle>
    <logo>https://saoyear.github.io/images/avatar.png</logo>
    <icon>https://saoyear.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Personal Page of Nian</rights>
    <entry>
        <title type="html"><![CDATA[NLP(自然语言处理) - Tricks & Dataset 集合]]></title>
        <id>https://saoyear.github.io/post/nlpzi-ran-yu-yan-chu-li-tricks-and-dataset-ji-he/</id>
        <link href="https://saoyear.github.io/post/nlpzi-ran-yu-yan-chu-li-tricks-and-dataset-ji-he/">
        </link>
        <updated>2020-07-27T09:35:42.000Z</updated>
        <content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>这是一篇NLP tricks的集合，在自然语言处理的模型中，有很多优化模型效果的技巧，其中很多技巧已经称为默认设置，不再文章中额外说明。这里持续更新一些方法作为记录。</p>
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#weight-average">Weight Average</a></li>
<li><a href="#adaptive-embedding">Adaptive Embedding</a></li>
<li><a href="#variational-dropout">Variational Dropout</a></li>
<li><a href="#sampled-softmax">Sampled Softmax</a></li>
<li><a href="#glue">GLUE</a></li>
</ul>
(技巧列表)</p>
<h1 id="weight-average">Weight Average</h1>
<p>Weight Average是一种自动集成方式，指的是在最终进行模型测试前，取前面每个checkpoint模型权重的平均值作为最终的测试模型。</p>
<h1 id="adaptive-embedding">Adaptive Embedding</h1>
<p>Adaptive embedding 是一种自适应词频的词嵌构建方法，通常用于<strong>词表较大的数据集</strong>（PTB这种小集就不用了）。这种方法的出发点是词频越高的词往往越容易出现一词多义的现象，同时其本身的含义也越丰富。<br>
同时伴随的一般是一组<strong>Cut-off</strong>值，这个值将词频分为了几个区间，比如[300000, 60000, 2000]。这时，在不同区间的词有不一样大小的词嵌矩阵。对任意一个词进行词嵌操作，会首先根据不同词频映射为不同大小的词嵌向量，再通过线性映射，统一投影为规定维度大小。如下图所示：<br>
<img src="https://img-blog.csdnimg.cn/20200701154500689.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NTA5ODIz,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" loading="lazy"><br>
高频词<strong>The</strong>和<strong>little</strong>通过高频词表转化为维度为d的词向量，而低频词<strong>dog</strong>转化为维度为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>d</mi><msup><mi>k</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msup></mfrac></mrow><annotation encoding="application/x-tex">\frac{d}{k^{n-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的词向量，而后再将这些向量映射到d维的向量作为输入的token。</p>
<h1 id="variational-dropout">Variational Dropout</h1>
<p>依据AWD-LSTM给出的解释，Variational Dropout不同于标准的Dropout，在每层，每次传递信息时使用Dropout都会随机生成一个Dropout mask。Variational Dropout会在第一次执行时就确定一个固定的Dropout mask。这个mask只会在下一个mini-batch时改变。</p>
<h1 id="sampled-softmax">Sampled Softmax</h1>
<p>当我们在做语言模型或其他NLP任务时，每一步的输出很有可能是一个词。一般来说，我们输出这个词的策略是在最后一层输出一个词表大小的向量，然后使用softmax函数对这个向量的每一个元素打分，根据打分（或概率）的结果输出这个词。而这样做有一个很大的弊端，就是当词表非常大的时候，我们每一次进行输出都要遍历一遍词表。<br>
<a href="https://arxiv.org/pdf/1412.2007.pdf">Bengio（原文章）</a>提出我们可以针对每个mini-batch汇总一次词表，以减小每次输出时遍历造成的高额运算，这就是Sampled Softmax。</p>
<h1 id="glue">GLUE</h1>
<p>GLUE全称为General Language Understanding Evaluation，可以访问其<a href="https://gluebenchmark.com/">benchmark官网</a>。 其中分为了多个任务，以下表格详细说明：</p>
<table>
<thead>
<tr>
<th>Task name</th>
<th>中文翻译</th>
<th>数据集说明</th>
<th>评估矩阵</th>
</tr>
</thead>
<tbody>
<tr>
<td>CoLA <br/> (The Corpus of Linguistic Acceptability)</td>
<td>评估数据集语法接受程度</td>
<td>单句的二分类问题, 判断一个英文句子在语法上是不是可接受的</td>
<td>Matthew's Corr</td>
</tr>
<tr>
<td>SST-2 <br/> (The Stanford Sentiment Treebank)</td>
<td>标准情感数据集</td>
<td>单句的二分类问题, 句子的来源于人们对一部电影的评价 <br/> 判断这个句子的情感倾向为 Positive/Negative</td>
<td>Accuracy</td>
</tr>
<tr>
<td>MRPC <br/> (Microsoft Research Paraphrase Corpus)</td>
<td>微软复述语料库</td>
<td>句子对来源于对同一条新闻的评论 <br/> 判断这一对句子在语义上是否相同</td>
<td>F1/Accuracy</td>
</tr>
<tr>
<td>STS-B <br/> (Semantic Textual Similarity Benchmark)</td>
<td>语义文本相似度数据</td>
<td>类似回归问题,给出一对句子 <br/> 使用1~5的评分评价两者在语义上的相似程度</td>
<td>Pearson-Spearman Corr</td>
</tr>
<tr>
<td>QQP <br/> (Quora Question Pairs)</td>
<td>Quara问题对</td>
<td>Quora 上的问题答案数据集, 目的是判断两个来自于Quora的问题句子在语义上是否是等价的</td>
<td>F1 / Accuracy</td>
</tr>
<tr>
<td>MNLI <br/> (MultiNL - matched/mismached)</td>
<td>多自然语言句型/跨句型匹配</td>
<td>推断两个句子是意思相近, 矛盾, 还是无关</td>
<td>Accuracy</td>
</tr>
<tr>
<td>QNLI <br/> (Question NLI)</td>
<td>自然语言问题推断</td>
<td>二分类问题, 两个句子是一个QA对 <br/> 正样本为Answer是对应Question的答案, 负样本为不是</td>
<td>Accuracy</td>
</tr>
<tr>
<td>RTE <br/> (Recognizing Textual Entailment)</td>
<td>文本蕴含识别</td>
<td>二分类问题, 判断两个句子是否意思相近, 但是数据量较少</td>
<td>Accuracy</td>
</tr>
<tr>
<td>WNLI <br/> (Winograd NLI)</td>
<td>自然语言推理数据集</td>
<td>推断两个句子是意思相近, 矛盾, 还是无关</td>
<td>Accuracy</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
</feed>